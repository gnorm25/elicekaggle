{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 데이터 전처리 함수\n",
    "def preprocess_data(df):\n",
    "    # 시간 데이터 처리 (시, 분, 초, minsec 생성)\n",
    "    df['hour'] = df['time_stamp'].str.slice(start=11, stop=13).astype(int)\n",
    "    df['minute'] = df['time_stamp'].str.slice(start=14, stop=16).astype(int)\n",
    "    df['second'] = df['time_stamp'].str.slice(start=17, stop=19).astype(int)\n",
    "    df['minsec'] = df['minute'] * 60 + df['second']\n",
    "\n",
    "    # \"Setpoint\" 컬럼 제거\n",
    "    df = df.drop(columns=[col for col in df.columns if 'Setpoint' in col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Stage별 데이터 분리 함수\n",
    "def split_stage_data(df):\n",
    "    # Stage 1 데이터 분리 (Machine 1, 2, 3 + Stage1.Output 관련 feature들)\n",
    "    stage1_data = df[df.columns.drop(list(df.filter(regex='Machine4|Machine5|Stage2')))]\n",
    "    \n",
    "    # Stage 2 데이터 분리 (Machine 4, 5 + Stage2.Output 관련 feature들)\n",
    "    stage2_data = df[df.columns.drop(list(df.filter(regex='Machine1|Machine2|Machine3|Stage1')))]\n",
    "    \n",
    "    return stage1_data, stage2_data\n",
    "\n",
    "# 모델 학습 함수\n",
    "def train_model(X, y, model_type='random_forest'):\n",
    "    if model_type == 'random_forest':\n",
    "        model = RandomForestRegressor(n_estimators=500, random_state=0, n_jobs=-1)\n",
    "    elif model_type == 'extra_trees':\n",
    "        model = ExtraTreesRegressor(n_estimators=500, random_state=0, n_jobs=-1)\n",
    "    \n",
    "    # tqdm으로 학습 진행 상황 확인\n",
    "    for _ in tqdm(range(1)):\n",
    "        model.fit(X, y)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 예측 함수\n",
    "def predict_model(model, X):\n",
    "    return model.predict(X)\n",
    "\n",
    "# 최종 R2 Score 계산 함수\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    return r2_score(y_true, y_pred)\n",
    "\n",
    "# 최종 서브미션 파일 저장 함수\n",
    "def save_submission(predictions_stage1, predictions_stage2):\n",
    "    np.save(\"submission1.npy\", predictions_stage1)\n",
    "    np.save(\"submission2.npy\", predictions_stage2)\n",
    "    print(\"Submission files 'submission1.npy' and 'submission2.npy' have been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 로드 및 전처리\n",
    "df = pd.read_csv('data/continuous_factory_process.csv')\n",
    "submission_df = pd.read_csv('data/submission_data.csv')\n",
    "\n",
    "df = preprocess_data(df)\n",
    "submission_df = preprocess_data(submission_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time_stamp', 'AmbientConditions.AmbientHumidity.U.Actual',\n",
       "       'AmbientConditions.AmbientTemperature.U.Actual',\n",
       "       'Machine1.RawMaterial.Property1', 'Machine1.RawMaterial.Property2',\n",
       "       'Machine1.RawMaterial.Property3', 'Machine1.RawMaterial.Property4',\n",
       "       'Machine1.RawMaterialFeederParameter.U.Actual',\n",
       "       'Machine1.Zone1Temperature.C.Actual',\n",
       "       'Machine1.Zone2Temperature.C.Actual', 'Machine1.MotorAmperage.U.Actual',\n",
       "       'Machine1.MotorRPM.C.Actual', 'Machine1.MaterialPressure.U.Actual',\n",
       "       'Machine1.MaterialTemperature.U.Actual',\n",
       "       'Machine1.ExitZoneTemperature.C.Actual',\n",
       "       'Machine2.RawMaterial.Property1', 'Machine2.RawMaterial.Property2',\n",
       "       'Machine2.RawMaterial.Property3', 'Machine2.RawMaterial.Property4',\n",
       "       'Machine2.RawMaterialFeederParameter.U.Actual',\n",
       "       'Machine2.Zone1Temperature.C.Actual',\n",
       "       'Machine2.Zone2Temperature.C.Actual', 'Machine2.MotorAmperage.U.Actual',\n",
       "       'Machine2.MotorRPM.C.Actual', 'Machine2.MaterialPressure.U.Actual',\n",
       "       'Machine2.MaterialTemperature.U.Actual',\n",
       "       'Machine2.ExitZoneTemperature.C.Actual',\n",
       "       'Machine3.RawMaterial.Property1', 'Machine3.RawMaterial.Property2',\n",
       "       'Machine3.RawMaterial.Property3', 'Machine3.RawMaterial.Property4',\n",
       "       'Machine3.RawMaterialFeederParameter.U.Actual',\n",
       "       'Machine3.Zone1Temperature.C.Actual',\n",
       "       'Machine3.Zone2Temperature.C.Actual', 'Machine3.MotorAmperage.U.Actual',\n",
       "       'Machine3.MotorRPM.C.Actual', 'Machine3.MaterialPressure.U.Actual',\n",
       "       'Machine3.MaterialTemperature.U.Actual',\n",
       "       'Machine3.ExitZoneTemperature.C.Actual',\n",
       "       'FirstStage.CombinerOperation.Temperature1.U.Actual',\n",
       "       'FirstStage.CombinerOperation.Temperature2.U.Actual',\n",
       "       'FirstStage.CombinerOperation.Temperature3.C.Actual',\n",
       "       'Stage1.Output.Measurement0.U.Actual',\n",
       "       'Stage1.Output.Measurement1.U.Actual',\n",
       "       'Stage1.Output.Measurement2.U.Actual',\n",
       "       'Stage1.Output.Measurement3.U.Actual',\n",
       "       'Stage1.Output.Measurement4.U.Actual',\n",
       "       'Stage1.Output.Measurement5.U.Actual',\n",
       "       'Stage1.Output.Measurement6.U.Actual',\n",
       "       'Stage1.Output.Measurement7.U.Actual',\n",
       "       'Stage1.Output.Measurement8.U.Actual',\n",
       "       'Stage1.Output.Measurement9.U.Actual',\n",
       "       'Stage1.Output.Measurement10.U.Actual',\n",
       "       'Stage1.Output.Measurement11.U.Actual',\n",
       "       'Stage1.Output.Measurement12.U.Actual',\n",
       "       'Stage1.Output.Measurement13.U.Actual',\n",
       "       'Stage1.Output.Measurement14.U.Actual',\n",
       "       'Machine4.Temperature1.C.Actual', 'Machine4.Temperature2.C.Actual',\n",
       "       'Machine4.Pressure.C.Actual', 'Machine4.Temperature3.C.Actual',\n",
       "       'Machine4.Temperature4.C.Actual', 'Machine4.Temperature5.C.Actual',\n",
       "       'Machine4.ExitTemperature.U.Actual', 'Machine5.Temperature1.C.Actual',\n",
       "       'Machine5.Temperature2.C.Actual', 'Machine5.Temperature3.C.Actual',\n",
       "       'Machine5.Temperature4.C.Actual', 'Machine5.Temperature5.C.Actual',\n",
       "       'Machine5.Temperature6.C.Actual', 'Machine5.ExitTemperature.U.Actual',\n",
       "       'Stage2.Output.Measurement0.U.Actual',\n",
       "       'Stage2.Output.Measurement1.U.Actual',\n",
       "       'Stage2.Output.Measurement2.U.Actual',\n",
       "       'Stage2.Output.Measurement3.U.Actual',\n",
       "       'Stage2.Output.Measurement4.U.Actual',\n",
       "       'Stage2.Output.Measurement5.U.Actual',\n",
       "       'Stage2.Output.Measurement6.U.Actual',\n",
       "       'Stage2.Output.Measurement7.U.Actual',\n",
       "       'Stage2.Output.Measurement8.U.Actual',\n",
       "       'Stage2.Output.Measurement9.U.Actual',\n",
       "       'Stage2.Output.Measurement10.U.Actual',\n",
       "       'Stage2.Output.Measurement11.U.Actual',\n",
       "       'Stage2.Output.Measurement12.U.Actual',\n",
       "       'Stage2.Output.Measurement13.U.Actual',\n",
       "       'Stage2.Output.Measurement14.U.Actual', 'hour', 'minute', 'second',\n",
       "       'minsec'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Stage 데이터 분리\n",
    "stage1_data, stage2_data = split_stage_data(df)\n",
    "submission_stage1_data, submission_stage2_data = split_stage_data(submission_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time_stamp', 'AmbientConditions.AmbientHumidity.U.Actual',\n",
       "       'AmbientConditions.AmbientTemperature.U.Actual',\n",
       "       'Machine1.RawMaterial.Property1', 'Machine1.RawMaterial.Property2',\n",
       "       'Machine1.RawMaterial.Property3', 'Machine1.RawMaterial.Property4',\n",
       "       'Machine1.RawMaterialFeederParameter.U.Actual',\n",
       "       'Machine1.Zone1Temperature.C.Actual',\n",
       "       'Machine1.Zone2Temperature.C.Actual', 'Machine1.MotorAmperage.U.Actual',\n",
       "       'Machine1.MotorRPM.C.Actual', 'Machine1.MaterialPressure.U.Actual',\n",
       "       'Machine1.MaterialTemperature.U.Actual',\n",
       "       'Machine1.ExitZoneTemperature.C.Actual',\n",
       "       'Machine2.RawMaterial.Property1', 'Machine2.RawMaterial.Property2',\n",
       "       'Machine2.RawMaterial.Property3', 'Machine2.RawMaterial.Property4',\n",
       "       'Machine2.RawMaterialFeederParameter.U.Actual',\n",
       "       'Machine2.Zone1Temperature.C.Actual',\n",
       "       'Machine2.Zone2Temperature.C.Actual', 'Machine2.MotorAmperage.U.Actual',\n",
       "       'Machine2.MotorRPM.C.Actual', 'Machine2.MaterialPressure.U.Actual',\n",
       "       'Machine2.MaterialTemperature.U.Actual',\n",
       "       'Machine2.ExitZoneTemperature.C.Actual',\n",
       "       'Machine3.RawMaterial.Property1', 'Machine3.RawMaterial.Property2',\n",
       "       'Machine3.RawMaterial.Property3', 'Machine3.RawMaterial.Property4',\n",
       "       'Machine3.RawMaterialFeederParameter.U.Actual',\n",
       "       'Machine3.Zone1Temperature.C.Actual',\n",
       "       'Machine3.Zone2Temperature.C.Actual', 'Machine3.MotorAmperage.U.Actual',\n",
       "       'Machine3.MotorRPM.C.Actual', 'Machine3.MaterialPressure.U.Actual',\n",
       "       'Machine3.MaterialTemperature.U.Actual',\n",
       "       'Machine3.ExitZoneTemperature.C.Actual',\n",
       "       'FirstStage.CombinerOperation.Temperature1.U.Actual',\n",
       "       'FirstStage.CombinerOperation.Temperature2.U.Actual',\n",
       "       'FirstStage.CombinerOperation.Temperature3.C.Actual',\n",
       "       'Stage1.Output.Measurement0.U.Actual',\n",
       "       'Stage1.Output.Measurement1.U.Actual',\n",
       "       'Stage1.Output.Measurement2.U.Actual',\n",
       "       'Stage1.Output.Measurement3.U.Actual',\n",
       "       'Stage1.Output.Measurement4.U.Actual',\n",
       "       'Stage1.Output.Measurement5.U.Actual',\n",
       "       'Stage1.Output.Measurement6.U.Actual',\n",
       "       'Stage1.Output.Measurement7.U.Actual',\n",
       "       'Stage1.Output.Measurement8.U.Actual',\n",
       "       'Stage1.Output.Measurement9.U.Actual',\n",
       "       'Stage1.Output.Measurement10.U.Actual',\n",
       "       'Stage1.Output.Measurement11.U.Actual',\n",
       "       'Stage1.Output.Measurement12.U.Actual',\n",
       "       'Stage1.Output.Measurement13.U.Actual',\n",
       "       'Stage1.Output.Measurement14.U.Actual', 'hour', 'minute', 'second',\n",
       "       'minsec'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage1_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Feature와 Target 설정 (Stage 1, Stage 2)\n",
    "X_stage1 = stage1_data[important_features]\n",
    "y_stage1 = stage1_data[[col for col in stage1_data.columns if 'Stage1.Output' in col]]\n",
    "\n",
    "X_stage2 = stage2_data[important_features_stage2]\n",
    "y_stage2 = stage2_data[[col for col in stage2_data.columns if 'Stage2.Output' in col]]\n",
    "\n",
    "X_submission_stage1 = submission_stage1_data[important_features]\n",
    "X_submission_stage2 = submission_stage2_data[important_features_stage2]\n",
    "\n",
    "# 4. 모델 학습 (Stage 1: RandomForest, Stage 2: ExtraTrees)\n",
    "model_rf_stage1 = train_model(X_stage1, y_stage1, model_type='random_forest')\n",
    "model_et_stage2 = train_model(X_stage2, y_stage2, model_type='extra_trees')\n",
    "\n",
    "# 5. 예측 수행\n",
    "submission_stage1_predictions = predict_model(model_rf_stage1, X_submission_stage1)\n",
    "submission_stage2_predictions = predict_model(model_et_stage2, X_submission_stage2)\n",
    "\n",
    "# 6. 서브미션 파일 저장\n",
    "save_submission(submission_stage1_predictions, submission_stage2_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine 1 컬럼 개수: 12\n",
      "Machine 2 컬럼 개수: 12\n",
      "Machine 3 컬럼 개수: 12\n",
      "Machine 4 컬럼 개수: 7\n",
      "Machine 5 컬럼 개수: 7\n"
     ]
    }
   ],
   "source": [
    "# Setpoint 컬럼 제거\n",
    "df_clean = df.drop(columns=[col for col in df.columns if 'Setpoint' in col])\n",
    "\n",
    "# Machine 1, 2, 3 (Stage 1)과 Machine 4, 5 (Stage 2)의 컬럼 개수 확인\n",
    "machine_1_columns = [col for col in df_clean.columns if 'Machine1' in col]\n",
    "machine_2_columns = [col for col in df_clean.columns if 'Machine2' in col]\n",
    "machine_3_columns = [col for col in df_clean.columns if 'Machine3' in col]\n",
    "machine_4_columns = [col for col in df_clean.columns if 'Machine4' in col]\n",
    "machine_5_columns = [col for col in df_clean.columns if 'Machine5' in col]\n",
    "\n",
    "# 각 Machine별 컬럼 개수 출력\n",
    "print(f\"Machine 1 컬럼 개수: {len(machine_1_columns)}\")\n",
    "print(f\"Machine 2 컬럼 개수: {len(machine_2_columns)}\")\n",
    "print(f\"Machine 3 컬럼 개수: {len(machine_3_columns)}\")\n",
    "print(f\"Machine 4 컬럼 개수: {len(machine_4_columns)}\")\n",
    "print(f\"Machine 5 컬럼 개수: {len(machine_5_columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 데이터 전처리 함수\n",
    "def preprocess_data(df):\n",
    "    # 시간 데이터 처리 (시, 분, 초, minsec 생성)\n",
    "    df['hour'] = df['time_stamp'].str.slice(start=11, stop=13).astype(int)\n",
    "    df['minute'] = df['time_stamp'].str.slice(start=14, stop=16).astype(int)\n",
    "    df['second'] = df['time_stamp'].str.slice(start=17, stop=19).astype(int)\n",
    "    df['minsec'] = df['minute'] * 60 + df['second']\n",
    "\n",
    "    # \"Setpoint\" 컬럼 제거\n",
    "    df = df.drop(columns=[col for col in df.columns if 'Setpoint' in col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 시간 데이터를 주기적인 sin, cos 형태로 변환\n",
    "def add_time_features(df):\n",
    "    # 각 시간 관련 컬럼을 주기성을 반영하여 변환\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "\n",
    "    df['minute_sin'] = np.sin(2 * np.pi * df['minute'] / 60)\n",
    "    df['minute_cos'] = np.cos(2 * np.pi * df['minute'] / 60)\n",
    "\n",
    "    df['second_sin'] = np.sin(2 * np.pi * df['second'] / 60)\n",
    "    df['second_cos'] = np.cos(2 * np.pi * df['second'] / 60)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Stage별 데이터 분리 함수\n",
    "def split_stage_data(df):\n",
    "    # 공통으로 사용될 환경 조건 컬럼 (Stage 1과 Stage 2에 모두 포함)\n",
    "    env_features = ['AmbientConditions.AmbientHumidity.U.Actual', \n",
    "                    'AmbientConditions.AmbientTemperature.U.Actual']\n",
    "    \n",
    "    # Stage 1 데이터 분리 (Machine 1, 2, 3 + Stage1.Output 관련 feature들 + 환경 조건 컬럼 + FirstStage Operation 관련 컬럼)\n",
    "    stage1_data = df[df.columns.drop(list(df.filter(regex='Machine4|Machine5|Stage2|time_stamp')))].copy()\n",
    "    stage1_data = stage1_data[env_features + stage1_data.columns.tolist()]  # 환경 조건 추가\n",
    "    \n",
    "    # Stage 2 데이터 분리 (Machine 4, 5 + Stage2.Output 관련 feature들 + 환경 조건 컬럼)\n",
    "    stage2_data = df[df.columns.drop(list(df.filter(regex='Machine1|Machine2|Machine3|Stage1|time_stamp|FirstStage.CombinerOperation')))].copy()\n",
    "    stage2_data = stage2_data[env_features + stage2_data.columns.tolist()]  # 환경 조건 추가\n",
    "    \n",
    "    return stage1_data, stage2_data\n",
    "\n",
    "# 모델 학습 함수\n",
    "def train_model(X, y, model_type='random_forest'):\n",
    "    if model_type == 'random_forest':\n",
    "        model = RandomForestRegressor(n_estimators=500, random_state=0, n_jobs=-1)\n",
    "    elif model_type == 'extra_trees':\n",
    "        model = ExtraTreesRegressor(n_estimators=500, random_state=0, n_jobs=-1)\n",
    "    \n",
    "    # tqdm으로 학습 진행 상황 확인\n",
    "    for _ in tqdm(range(1)):\n",
    "        model.fit(X, y)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 예측 함수\n",
    "def predict_model(model, X):\n",
    "    return model.predict(X)\n",
    "\n",
    "# 최종 서브미션 파일 저장 함수\n",
    "def save_submission(predictions_stage1, predictions_stage2):\n",
    "    np.save(\"submission1.npy\", predictions_stage1)\n",
    "    np.save(\"submission2.npy\", predictions_stage2)\n",
    "    print(\"Submission files 'submission1.npy' and 'submission2.npy' have been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:24<00:00, 24.41s/it]\n",
      "100%|██████████| 1/1 [01:07<00:00, 67.31s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m         X_submission_stage2[col] \u001b[38;5;241m=\u001b[39m X_submission_stage2[col]\u001b[38;5;241m.\u001b[39mastype(train_dtype)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# 예측 수행 (학습 시와 동일한 feature 순서로 예측)\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m submission_stage1_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_rf_stage1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_submission_stage1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m submission_stage2_predictions \u001b[38;5;241m=\u001b[39m predict_model(model_et_stage2, X_submission_stage2)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# 6. 서브미션 파일 저장\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[57], line 64\u001b[0m, in \u001b[0;36mpredict_model\u001b[0;34m(model, X)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_model\u001b[39m(model, X):\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/module01/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:1063\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1061\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m-> 1063\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/miniconda3/envs/module01/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/module01/lib/python3.12/site-packages/sklearn/base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/module01/lib/python3.12/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. 데이터 로드 및 전처리\n",
    "df = pd.read_csv('data/continuous_factory_process.csv')\n",
    "submission_df = pd.read_csv('data/submission_data.csv')\n",
    "\n",
    "df = preprocess_data(df)\n",
    "submission_df = preprocess_data(submission_df)\n",
    "\n",
    "# 시간 관련 데이터 변환\n",
    "df = add_time_features(df)\n",
    "submission_df = add_time_features(submission_df)\n",
    "\n",
    "# 2. Stage 데이터 분리\n",
    "stage1_data, stage2_data = split_stage_data(df)\n",
    "submission_stage1_data, submission_stage2_data = split_stage_data(submission_df)\n",
    "\n",
    "# 3. Feature와 Target 설정 (Stage 1, Stage 2)\n",
    "X_stage1 = stage1_data.drop(columns=[col for col in stage1_data.columns if 'Stage1.Output' in col])\n",
    "y_stage1 = stage1_data[[col for col in stage1_data.columns if 'Stage1.Output' in col]]\n",
    "\n",
    "X_stage2 = stage2_data.drop(columns=[col for col in stage2_data.columns if 'Stage2.Output' in col])\n",
    "y_stage2 = stage2_data[[col for col in stage2_data.columns if 'Stage2.Output' in col]]\n",
    "\n",
    "# 학습에 사용한 feature 이름과 순서 저장\n",
    "stage1_features = X_stage1.columns.tolist()\n",
    "stage2_features = X_stage2.columns.tolist()\n",
    "\n",
    "# 4. 모델 학습 (Stage 1: RandomForest, Stage 2: ExtraTrees)\n",
    "model_rf_stage1 = train_model(X_stage1, y_stage1, model_type='random_forest')\n",
    "model_et_stage2 = train_model(X_stage2, y_stage2, model_type='extra_trees')\n",
    "\n",
    "# 5. submission 데이터에서 학습 시 사용된 feature 순서를 그대로 맞춰줌\n",
    "X_submission_stage1 = submission_stage1_data[stage1_features]  # 동일한 feature 순서 강제 적용\n",
    "X_submission_stage2 = submission_stage2_data[stage2_features]  # 동일한 feature 순서 강제 적용\n",
    "\n",
    "# 학습 시 사용한 feature와 submission 데이터의 feature 타입 비교 및 타입 변환\n",
    "for col in X_stage1.columns:\n",
    "    train_dtype = X_stage1[col].values.dtype\n",
    "    submission_dtype = X_submission_stage1[col].values.dtype\n",
    "    if train_dtype != submission_dtype:\n",
    "        print(f\"Converting {col} from {submission_dtype} to {train_dtype}\")\n",
    "        X_submission_stage1[col] = X_submission_stage1[col].astype(train_dtype)\n",
    "\n",
    "# 동일하게 Stage 2 데이터에도 적용\n",
    "for col in X_stage2.columns:\n",
    "    train_dtype = X_stage2[col].values.dtype\n",
    "    submission_dtype = X_submission_stage2[col].values.dtype\n",
    "    if train_dtype != submission_dtype:\n",
    "        print(f\"Converting {col} from {submission_dtype} to {train_dtype}\")\n",
    "        X_submission_stage2[col] = X_submission_stage2[col].astype(train_dtype)\n",
    "\n",
    "# 예측 수행 (학습 시와 동일한 feature 순서로 예측)\n",
    "submission_stage1_predictions = predict_model(model_rf_stage1, X_submission_stage1)\n",
    "submission_stage2_predictions = predict_model(model_et_stage2, X_submission_stage2)\n",
    "\n",
    "# 6. 서브미션 파일 저장\n",
    "save_submission(submission_stage1_predictions, submission_stage2_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 Feature Names Comparison\n",
      "Mismatch at index 1: AmbientConditions.AmbientTemperature.U.Actual (train) != AmbientConditions.AmbientHumidity.U.Actual (submission)\n",
      "Mismatch at index 2: AmbientConditions.AmbientHumidity.U.Actual (train) != AmbientConditions.AmbientTemperature.U.Actual (submission)\n",
      "Mismatch at index 4: Machine1.RawMaterial.Property1 (train) != AmbientConditions.AmbientHumidity.U.Actual (submission)\n",
      "Mismatch at index 5: Machine1.RawMaterial.Property2 (train) != AmbientConditions.AmbientHumidity.U.Actual (submission)\n",
      "Mismatch at index 6: Machine1.RawMaterial.Property3 (train) != AmbientConditions.AmbientTemperature.U.Actual (submission)\n",
      "Mismatch at index 7: Machine1.RawMaterial.Property4 (train) != AmbientConditions.AmbientTemperature.U.Actual (submission)\n",
      "Mismatch at index 8: Machine1.RawMaterialFeederParameter.U.Actual (train) != Machine1.RawMaterial.Property1 (submission)\n",
      "Mismatch at index 9: Machine1.Zone1Temperature.C.Actual (train) != Machine1.RawMaterial.Property2 (submission)\n",
      "Mismatch at index 10: Machine1.Zone2Temperature.C.Actual (train) != Machine1.RawMaterial.Property3 (submission)\n",
      "Mismatch at index 11: Machine1.MotorAmperage.U.Actual (train) != Machine1.RawMaterial.Property4 (submission)\n",
      "Mismatch at index 12: Machine1.MotorRPM.C.Actual (train) != Machine1.RawMaterialFeederParameter.U.Actual (submission)\n",
      "Mismatch at index 13: Machine1.MaterialPressure.U.Actual (train) != Machine1.Zone1Temperature.C.Actual (submission)\n",
      "Mismatch at index 14: Machine1.MaterialTemperature.U.Actual (train) != Machine1.Zone2Temperature.C.Actual (submission)\n",
      "Mismatch at index 15: Machine1.ExitZoneTemperature.C.Actual (train) != Machine1.MotorAmperage.U.Actual (submission)\n",
      "Mismatch at index 16: Machine2.RawMaterial.Property1 (train) != Machine1.MotorRPM.C.Actual (submission)\n",
      "Mismatch at index 17: Machine2.RawMaterial.Property2 (train) != Machine1.MaterialPressure.U.Actual (submission)\n",
      "Mismatch at index 18: Machine2.RawMaterial.Property3 (train) != Machine1.MaterialTemperature.U.Actual (submission)\n",
      "Mismatch at index 19: Machine2.RawMaterial.Property4 (train) != Machine1.ExitZoneTemperature.C.Actual (submission)\n",
      "Mismatch at index 20: Machine2.RawMaterialFeederParameter.U.Actual (train) != Machine2.RawMaterial.Property1 (submission)\n",
      "Mismatch at index 21: Machine2.Zone1Temperature.C.Actual (train) != Machine2.RawMaterial.Property2 (submission)\n",
      "Mismatch at index 22: Machine2.Zone2Temperature.C.Actual (train) != Machine2.RawMaterial.Property3 (submission)\n",
      "Mismatch at index 23: Machine2.MotorAmperage.U.Actual (train) != Machine2.RawMaterial.Property4 (submission)\n",
      "Mismatch at index 24: Machine2.MotorRPM.C.Actual (train) != Machine2.RawMaterialFeederParameter.U.Actual (submission)\n",
      "Mismatch at index 25: Machine2.MaterialPressure.U.Actual (train) != Machine2.Zone1Temperature.C.Actual (submission)\n",
      "Mismatch at index 26: Machine2.MaterialTemperature.U.Actual (train) != Machine2.Zone2Temperature.C.Actual (submission)\n",
      "Mismatch at index 27: Machine2.ExitZoneTemperature.C.Actual (train) != Machine2.MotorAmperage.U.Actual (submission)\n",
      "Mismatch at index 28: Machine3.RawMaterial.Property1 (train) != Machine2.MotorRPM.C.Actual (submission)\n",
      "Mismatch at index 29: Machine3.RawMaterial.Property2 (train) != Machine2.MaterialPressure.U.Actual (submission)\n",
      "Mismatch at index 30: Machine3.RawMaterial.Property3 (train) != Machine2.MaterialTemperature.U.Actual (submission)\n",
      "Mismatch at index 31: Machine3.RawMaterial.Property4 (train) != Machine2.ExitZoneTemperature.C.Actual (submission)\n",
      "Mismatch at index 32: Machine3.RawMaterialFeederParameter.U.Actual (train) != Machine3.RawMaterial.Property1 (submission)\n",
      "Mismatch at index 33: Machine3.Zone1Temperature.C.Actual (train) != Machine3.RawMaterial.Property2 (submission)\n",
      "Mismatch at index 34: Machine3.Zone2Temperature.C.Actual (train) != Machine3.RawMaterial.Property3 (submission)\n",
      "Mismatch at index 35: Machine3.MotorAmperage.U.Actual (train) != Machine3.RawMaterial.Property4 (submission)\n",
      "Mismatch at index 36: Machine3.MotorRPM.C.Actual (train) != Machine3.RawMaterialFeederParameter.U.Actual (submission)\n",
      "Mismatch at index 37: Machine3.MaterialPressure.U.Actual (train) != Machine3.Zone1Temperature.C.Actual (submission)\n",
      "Mismatch at index 38: Machine3.MaterialTemperature.U.Actual (train) != Machine3.Zone2Temperature.C.Actual (submission)\n",
      "Mismatch at index 39: Machine3.ExitZoneTemperature.C.Actual (train) != Machine3.MotorAmperage.U.Actual (submission)\n",
      "Mismatch at index 40: FirstStage.CombinerOperation.Temperature1.U.Actual (train) != Machine3.MotorRPM.C.Actual (submission)\n",
      "Mismatch at index 41: FirstStage.CombinerOperation.Temperature2.U.Actual (train) != Machine3.MaterialPressure.U.Actual (submission)\n",
      "Mismatch at index 42: FirstStage.CombinerOperation.Temperature3.C.Actual (train) != Machine3.MaterialTemperature.U.Actual (submission)\n",
      "Mismatch at index 43: hour (train) != Machine3.ExitZoneTemperature.C.Actual (submission)\n",
      "Mismatch at index 44: minute (train) != FirstStage.CombinerOperation.Temperature1.U.Actual (submission)\n",
      "Mismatch at index 45: second (train) != FirstStage.CombinerOperation.Temperature2.U.Actual (submission)\n",
      "Mismatch at index 46: minsec (train) != FirstStage.CombinerOperation.Temperature3.C.Actual (submission)\n",
      "Mismatch at index 47: hour_sin (train) != hour (submission)\n",
      "Mismatch at index 48: hour_cos (train) != minute (submission)\n",
      "Mismatch at index 49: minute_sin (train) != second (submission)\n",
      "Mismatch at index 50: minute_cos (train) != minsec (submission)\n",
      "Mismatch at index 51: second_sin (train) != hour_sin (submission)\n",
      "Mismatch at index 52: second_cos (train) != hour_cos (submission)\n",
      "Stage 2 Feature Names Comparison\n",
      "Mismatch at index 1: AmbientConditions.AmbientTemperature.U.Actual (train) != AmbientConditions.AmbientHumidity.U.Actual (submission)\n",
      "Mismatch at index 2: AmbientConditions.AmbientHumidity.U.Actual (train) != AmbientConditions.AmbientTemperature.U.Actual (submission)\n",
      "Mismatch at index 4: Machine4.Temperature1.C.Actual (train) != AmbientConditions.AmbientHumidity.U.Actual (submission)\n",
      "Mismatch at index 5: Machine4.Temperature2.C.Actual (train) != AmbientConditions.AmbientHumidity.U.Actual (submission)\n",
      "Mismatch at index 6: Machine4.Pressure.C.Actual (train) != AmbientConditions.AmbientTemperature.U.Actual (submission)\n",
      "Mismatch at index 7: Machine4.Temperature3.C.Actual (train) != AmbientConditions.AmbientTemperature.U.Actual (submission)\n",
      "Mismatch at index 8: Machine4.Temperature4.C.Actual (train) != Machine4.Temperature1.C.Actual (submission)\n",
      "Mismatch at index 9: Machine4.Temperature5.C.Actual (train) != Machine4.Temperature2.C.Actual (submission)\n",
      "Mismatch at index 10: Machine4.ExitTemperature.U.Actual (train) != Machine4.Pressure.C.Actual (submission)\n",
      "Mismatch at index 11: Machine5.Temperature1.C.Actual (train) != Machine4.Temperature3.C.Actual (submission)\n",
      "Mismatch at index 12: Machine5.Temperature2.C.Actual (train) != Machine4.Temperature4.C.Actual (submission)\n",
      "Mismatch at index 13: Machine5.Temperature3.C.Actual (train) != Machine4.Temperature5.C.Actual (submission)\n",
      "Mismatch at index 14: Machine5.Temperature4.C.Actual (train) != Machine4.ExitTemperature.U.Actual (submission)\n",
      "Mismatch at index 15: Machine5.Temperature5.C.Actual (train) != Machine5.Temperature1.C.Actual (submission)\n",
      "Mismatch at index 16: Machine5.Temperature6.C.Actual (train) != Machine5.Temperature2.C.Actual (submission)\n",
      "Mismatch at index 17: Machine5.ExitTemperature.U.Actual (train) != Machine5.Temperature3.C.Actual (submission)\n",
      "Mismatch at index 18: hour (train) != Machine5.Temperature4.C.Actual (submission)\n",
      "Mismatch at index 19: minute (train) != Machine5.Temperature5.C.Actual (submission)\n",
      "Mismatch at index 20: second (train) != Machine5.Temperature6.C.Actual (submission)\n",
      "Mismatch at index 21: minsec (train) != Machine5.ExitTemperature.U.Actual (submission)\n",
      "Mismatch at index 22: hour_sin (train) != hour (submission)\n",
      "Mismatch at index 23: hour_cos (train) != minute (submission)\n",
      "Mismatch at index 24: minute_sin (train) != second (submission)\n",
      "Mismatch at index 25: minute_cos (train) != minsec (submission)\n",
      "Mismatch at index 26: second_sin (train) != hour_sin (submission)\n",
      "Mismatch at index 27: second_cos (train) != hour_cos (submission)\n"
     ]
    }
   ],
   "source": [
    "# 학습 시 사용한 feature와 submission 데이터의 feature 이름과 순서 비교\n",
    "print(\"Stage 1 Feature Names Comparison\")\n",
    "for i, (train_col, submission_col) in enumerate(zip(X_stage1.columns, X_submission_stage1.columns)):\n",
    "    if train_col != submission_col:\n",
    "        print(f\"Mismatch at index {i}: {train_col} (train) != {submission_col} (submission)\")\n",
    "\n",
    "print(\"Stage 2 Feature Names Comparison\")\n",
    "for i, (train_col, submission_col) in enumerate(zip(X_stage2.columns, X_submission_stage2.columns)):\n",
    "    if train_col != submission_col:\n",
    "        print(f\"Mismatch at index {i}: {train_col} (train) != {submission_col} (submission)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time_stamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/module01/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time_stamp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 73\u001b[0m\n\u001b[1;32m     70\u001b[0m submission_df \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/submission_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# 데이터 전처리\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m submission_df \u001b[38;5;241m=\u001b[39m preprocess_data(submission_df)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Stage 1, Stage 2 데이터 분리\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[63], line 17\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     15\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSetpoint\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m col])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 시간 관련 feature 생성\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhour\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime_stamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mhour\n\u001b[1;32m     18\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminute\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_stamp\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mminute\n\u001b[1;32m     19\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msecond\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_stamp\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39msecond\n",
      "File \u001b[0;32m~/miniconda3/envs/module01/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/module01/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time_stamp'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 데이터 불러오기\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# 2. 데이터 전처리 함수\n",
    "def preprocess_data(df):\n",
    "    # time_stamp 컬럼 제거\n",
    "    df = df.drop(columns=['time_stamp'])\n",
    "    df = df.drop(columns=[col for col in df.columns if 'Setpoint' in col])\n",
    "    # 시간 관련 feature 생성\n",
    "    df['hour'] = pd.to_datetime(df['time_stamp']).dt.hour\n",
    "    df['minute'] = pd.to_datetime(df['time_stamp']).dt.minute\n",
    "    df['second'] = pd.to_datetime(df['time_stamp']).dt.second\n",
    "    df['minsec'] = df['minute'] * 60 + df['second']\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['minute_sin'] = np.sin(2 * np.pi * df['minute'] / 60)\n",
    "    df['minute_cos'] = np.cos(2 * np.pi * df['minute'] / 60)\n",
    "    df['second_sin'] = np.sin(2 * np.pi * df['second'] / 60)\n",
    "    df['second_cos'] = np.cos(2 * np.pi * df['second'] / 60)\n",
    "    return df\n",
    "\n",
    "# 3. Stage 1, Stage 2 데이터 분리\n",
    "def split_stage_data(df):\n",
    "    stage1_data = df[df.columns.drop(list(df.filter(regex='Machine4|Machine5|Stage2')))]\n",
    "    stage2_data = df[df.columns.drop(list(df.filter(regex='Machine1|Machine2|Machine3|Stage1')))]\n",
    "    return stage1_data, stage2_data\n",
    "\n",
    "# 4. 모델 학습 함수\n",
    "def train_model(X, y, model_type=\"rf\"):\n",
    "    if model_type == \"rf\":\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    elif model_type == \"et\":\n",
    "        model = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "# 5. 예측 함수\n",
    "def predict_model(model, X):\n",
    "    return model.predict(X)\n",
    "\n",
    "# 6. 서브미션 파일 저장 함수\n",
    "def save_submission(stage1_preds, stage2_preds):\n",
    "    np.save('submission1.npy', stage1_preds)\n",
    "    np.save('submission2.npy', stage2_preds)\n",
    "\n",
    "# 7. 학습과 서브미션 피처의 순서 및 타입 맞추기\n",
    "def align_submission_features(X_train, X_submission):\n",
    "    for col in X_train.columns:\n",
    "        if col in X_submission.columns:\n",
    "            train_dtype = X_train[col].values.dtype\n",
    "            submission_dtype = X_submission[col].values.dtype\n",
    "            if train_dtype != submission_dtype:\n",
    "                X_submission[col] = X_submission[col].astype(train_dtype)\n",
    "\n",
    "    X_submission = X_submission[X_train.columns]  # 학습 시 사용한 피처 순서로 재배열\n",
    "    return X_submission\n",
    "\n",
    "# 메인 코드 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 불러오기\n",
    "    df = load_data('data/continuous_factory_process.csv')\n",
    "    submission_df = load_data('data/submission_data.csv')\n",
    "\n",
    "    # 데이터 전처리\n",
    "    df = preprocess_data(df)\n",
    "    submission_df = preprocess_data(submission_df)\n",
    "\n",
    "    # Stage 1, Stage 2 데이터 분리\n",
    "    stage1_data, stage2_data = split_stage_data(df)\n",
    "    submission_stage1_data, submission_stage2_data = split_stage_data(submission_df)\n",
    "\n",
    "    # 입력 피처(X)와 출력 타겟(y) 설정\n",
    "    stage1_features = stage1_data.drop(columns=[col for col in stage1_data.columns if 'Stage1.Output' in col])\n",
    "    stage1_target = stage1_data[[col for col in stage1_data.columns if 'Stage1.Output' in col]]\n",
    "\n",
    "    stage2_features = stage2_data.drop(columns=[col for col in stage2_data.columns if 'Stage2.Output' in col])\n",
    "    stage2_target = stage2_data[[col for col in stage2_data.columns if 'Stage2.Output' in col]]\n",
    "\n",
    "    # 학습/테스트 데이터 분리\n",
    "    X_stage1, X_stage1_test, y_stage1, y_stage1_test = train_test_split(stage1_features, stage1_target, test_size=0.2, random_state=42)\n",
    "    X_stage2, X_stage2_test, y_stage2, y_stage2_test = train_test_split(stage2_features, stage2_target, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 모델 학습\n",
    "    model_rf_stage1 = train_model(X_stage1, y_stage1, model_type=\"rf\")\n",
    "    model_et_stage2 = train_model(X_stage2, y_stage2, model_type=\"et\")\n",
    "\n",
    "    # submission 데이터의 피처 순서 및 타입 맞추기\n",
    "    X_submission_stage1 = align_submission_features(X_stage1, submission_stage1_data[stage1_features.columns])\n",
    "    X_submission_stage2 = align_submission_features(X_stage2, submission_stage2_data[stage2_features.columns])\n",
    "\n",
    "    # 예측 수행 (학습 시와 동일한 피처 순서로 예측)\n",
    "    submission_stage1_predictions = predict_model(model_rf_stage1, X_submission_stage1)\n",
    "    submission_stage2_predictions = predict_model(model_et_stage2, X_submission_stage2)\n",
    "\n",
    "    # 서브미션 파일 저장\n",
    "    save_submission(submission_stage1_predictions, submission_stage2_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 데이터 전처리 함수\n",
    "def preprocess_data(df):\n",
    "    # 시간 데이터 처리 (시, 분, 초, minsec 생성)\n",
    "    df['hour'] = df['time_stamp'].str.slice(start=11, stop=13).astype(int)\n",
    "    df['minute'] = df['time_stamp'].str.slice(start=14, stop=16).astype(int)\n",
    "    df['second'] = df['time_stamp'].str.slice(start=17, stop=19).astype(int)\n",
    "    df['minsec'] = df['minute'] * 60 + df['second']\n",
    "\n",
    "    # \"Setpoint\" 컬럼 제거\n",
    "    df = df.drop(columns=[col for col in df.columns if 'Setpoint' in col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 시간 데이터를 주기적인 sin, cos 형태로 변환\n",
    "def add_time_features(df):\n",
    "    # 각 시간 관련 컬럼을 주기성을 반영하여 변환\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "\n",
    "    df['minute_sin'] = np.sin(2 * np.pi * df['minute'] / 60)\n",
    "    df['minute_cos'] = np.cos(2 * np.pi * df['minute'] / 60)\n",
    "\n",
    "    df['second_sin'] = np.sin(2 * np.pi * df['second'] / 60)\n",
    "    df['second_cos'] = np.cos(2 * np.pi * df['second'] / 60)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Stage별 데이터 분리 함수\n",
    "def split_stage_data(df):\n",
    "    # 공통으로 사용될 환경 조건 컬럼 (Stage 1과 Stage 2에 모두 포함)\n",
    "    env_features = ['AmbientConditions.AmbientHumidity.U.Actual', \n",
    "                    'AmbientConditions.AmbientTemperature.U.Actual']\n",
    "    \n",
    "    # Stage 1 데이터 분리 (Machine 1, 2, 3 + Stage1.Output 관련 feature들 + 환경 조건 컬럼 + FirstStage Operation 관련 컬럼)\n",
    "    stage1_data = df[df.columns.drop(list(df.filter(regex='Machine4|Machine5|Stage2|time_stamp')))].copy()\n",
    "    stage1_data = stage1_data[env_features + stage1_data.columns.tolist()]  # 환경 조건 추가\n",
    "    \n",
    "    # Stage 2 데이터 분리 (Machine 4, 5 + Stage2.Output 관련 feature들 + 환경 조건 컬럼)\n",
    "    stage2_data = df[df.columns.drop(list(df.filter(regex='Machine1|Machine2|Machine3|Stage1|time_stamp|FirstStage.CombinerOperation')))].copy()\n",
    "    stage2_data = stage2_data[env_features + stage2_data.columns.tolist()]  # 환경 조건 추가\n",
    "    \n",
    "    return stage1_data, stage2_data\n",
    "\n",
    "# 모델 학습 함수 (KFold 적용)\n",
    "def train_model_kfold(X, y, model_type='random_forest', n_splits=5):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "    \n",
    "    if model_type == 'random_forest':\n",
    "        model = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
    "        param_grid = {\n",
    "            'n_estimators': [200, 500],\n",
    "            'max_depth': [10, 20, None],\n",
    "            'min_samples_split': [2, 5],\n",
    "        }\n",
    "    elif model_type == 'extra_trees':\n",
    "        model = ExtraTreesRegressor(random_state=0, n_jobs=-1)\n",
    "        param_grid = {\n",
    "            'n_estimators': [200, 500],\n",
    "            'max_depth': [10, 20, None],\n",
    "            'min_samples_split': [2, 5],\n",
    "        }\n",
    "\n",
    "    # GridSearch로 하이퍼파라미터 튜닝\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kfold, n_jobs=-1, verbose=2)\n",
    "    \n",
    "    best_model = None\n",
    "    best_score = -float('inf')\n",
    "\n",
    "    # tqdm으로 진행 상황 확인\n",
    "    for train_idx, val_idx in tqdm(kfold.split(X), total=n_splits):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        model = grid_search.best_estimator_\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        score = r2_score(y_val, y_pred)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "\n",
    "    print(f\"Best R2 Score: {best_score}\")\n",
    "    return best_model\n",
    "\n",
    "# R2 Score 계산 및 평가\n",
    "def evaluate_model_kfold(X, y, model, n_splits=5):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "    r2_scores = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "    avg_r2_score = np.mean(r2_scores)\n",
    "    print(f\"Average R2 Score: {avg_r2_score}\")\n",
    "    return avg_r2_score\n",
    "\n",
    "# 최종 서브미션 파일 저장 함수\n",
    "def save_submission(predictions_stage1, predictions_stage2):\n",
    "    np.save(\"submission1.npy\", predictions_stage1)\n",
    "    np.save(\"submission2.npy\", predictions_stage2)\n",
    "    print(\"Submission files 'submission1.npy' and 'submission2.npy' have been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. 데이터 로드 및 전처리\n",
    "df = pd.read_csv('data/continuous_factory_process.csv')\n",
    "submission_df = pd.read_csv('data/submission_data.csv')\n",
    "\n",
    "df = preprocess_data(df)\n",
    "submission_df = preprocess_data(submission_df)\n",
    "\n",
    "# 시간 관련 데이터 변환\n",
    "df = add_time_features(df)\n",
    "submission_df = add_time_features(submission_df)\n",
    "\n",
    "# 2. Stage 데이터 분리\n",
    "stage1_data, stage2_data = split_stage_data(df)\n",
    "submission_stage1_data, submission_stage2_data = split_stage_data(submission_df)\n",
    "\n",
    "# 3. Feature와 Target 설정 (Stage 1, Stage 2)\n",
    "X_stage1 = stage1_data.drop(columns=[col for col in stage1_data.columns if 'Stage1.Output' in col])\n",
    "y_stage1 = stage1_data[[col for col in stage1_data.columns if 'Stage1.Output' in col]]\n",
    "\n",
    "X_stage2 = stage2_data.drop(columns=[col for col in stage2_data.columns if 'Stage2.Output' in col])\n",
    "y_stage2 = stage2_data[[col for col in stage2_data.columns if 'Stage2.Output' in col]]\n",
    "\n",
    "X_submission_stage1 = submission_stage1_data[X_stage1.columns]\n",
    "X_submission_stage2 = submission_stage2_data[X_stage2.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=  36.8s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=  40.8s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=  36.4s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=  45.2s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=  46.0s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=  46.7s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=  55.6s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=  19.1s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=  32.6s\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=  36.4s\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=500; total time= 1.7min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=500; total time= 1.9min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=500; total time= 1.9min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=500; total time= 1.8min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=500; total time= 2.1min\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=500; total time= 1.5min\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=500; total time= 1.6min\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=500; total time= 1.6min\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=500; total time= 1.7min\n",
      "[CV] END max_depth=10, min_samples_split=5, n_estimators=500; total time= 1.8min\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time= 1.2min\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time= 1.6min\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time= 1.1min\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=  39.2s\n",
      "[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=  40.1s\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. 모델 학습 (Stage 1: RandomForest, Stage 2: ExtraTrees)\n",
    "model_rf_stage1 = train_model_kfold(X_stage1, y_stage1, model_type='random_forest', n_splits=5)\n",
    "model_et_stage2 = train_model_kfold(X_stage2, y_stage2, model_type='extra_trees', n_splits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. 예측 수행\n",
    "submission_stage1_predictions = model_rf_stage1.predict(X_submission_stage1)\n",
    "submission_stage2_predictions = model_et_stage2.predict(X_submission_stage2)\n",
    "\n",
    "# 6. 서브미션 파일 저장\n",
    "save_submission(submission_stage1_predictions, submission_stage2_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "module01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
